---
title: 'How It Works'
description: 'Works for Logs and Metrics'
type: how-it-works
hero:
 heading: "Works for Logs and Metrics"
 desc: "Fluent Bit was designed for speed, scale, and flexibility <br> in a very lightweight, efficient package."
 image: "/images/overview-new.svg"
 text: >
  An open source Log Processor and Forwarder which allows you to collect any data like metrics and logs\
   from different sources, enrich them with filters and send them to multiple destinations. 
preferred:
 heading: "An example of sending data to Kafka and Splunk"
 image: "/images/sending-data.svg"
advantage: true
btnAdvText: "Read documentation"
btnAdvUrl: "https://docs.fluentbit.io/manual"
linkNewTab: "true"
history:
  heading: "A Brief History of Fluent Bit"
  image: "/images/history.jpg"
  text: >
   In 2014, the Fluentd team at Treasure Data began to see the need for a more lightweight log processor to be used in resource-constrained environments like embedded Linux and gateways.  The objective was to **provide all the speed, scale, and flexibility** of Fluentd in a smaller, more efficient footprint. The result was Fluent Bit.


   While Fluent Bit did gain rapid adoption in embedded environments, its lightweight, efficient design also made it attractive to those working across the cloud.  Features to support more inputs, filters, and outputs were added, and Fluent Bit quickly **became the industry standard unified logging layer** across all cloud and containerized environments.
   
   
   **Fluent Bit has been deployed over a billion times and is trusted by some of the worldâ€™s largest and most complex organizations.**
---

## Overview

It has been designed as a lightweight solution with high performance in mind. From a design perspective, it's fully asynchronous (event-driven) and take the most of the operating systems API for performance and reliability.
